import os
import subprocess
import shutil
import re
import pysam

from os.path import join

configfile: config["cfp"]     
script_dir = config["script_dir"]          
name = config["name"] 
fasta_file = config["fasta"] 
edit = config["edit"] 

outdir = config["output"] 
barcode_tag = config["barcode_tag"] 
min_aq = config["min_aq"] 
keep_positions = config["keep_positions"] 
remove_positions = config["remove_positions"] 

# Determine .bam files to execute for fragment overlap analysis
infile1 = outdir + "/.internal/chrs.txt"

with open(infile1) as f:
    chrs = f.readlines()

chrs = [x.strip() for x in chrs] 
raw_awk_files = [outdir + '/temp/02_frombam/rawFromBam_' + x + ".txt" for x in chrs] 
processed_read_files = [outdir + '/temp/03_processed/merged_' + x + ".txt" for x in chrs] 
quant1s = [outdir + '/logs/readstats/' + "quant1." + x + ".txt" for x in chrs] 

# File path to scripts
intersect_reads_edits_R = script_dir + "/R/22_intersect_reads_edits.R"
munge_qc_edits_R = script_dir + "/R/04_mungeQC1.R"
filterMA_py = script_dir + "/python/21_process_master_awk_edit.py"

rule all:
	input:
		final_edit_file = outdir + "/" + name + ".edits.tsv.gz",
		final_qc1 = outdir + "/" + name + ".qcQuant.tsv"

# First up, pull out reads / bases that represent mismatches
# Adjust the strand because we can
rule pull_strand_bp_chr:
	input:
		bam = outdir + "/temp/01_split/splitBam." + "{chr}" + ".bam",
	output:
		master_awk_out1 = outdir + '/temp/02_frombam/rawFromBam_' + "{chr}" + ".txt"
	threads:
		1
	run:
		chr = wildcards.chr
		
		# Pull reads with a matching N mask adjusting for strand as needed
		samtools_calmd_log_F = outdir + '/logs/samtools/' + "master_bam_parse." + chr + "_F.txt"
		samtools_calmd_log_R = outdir + '/logs/samtools/' + "master_bam_parse." + chr + "_R.txt"
		
		# Temp stranded output files
		forward_ma = output.master_awk_out1 + "_F"
		reverse_ma = output.master_awk_out1 + "_R"
			
		forward_ma_py = output.master_awk_out1 + "_F_py"
		reverse_ma_py = output.master_awk_out1 + "_R_py"
		
		# Generate the forward strand calls
		sam_call1 = '(samtools view -F 0x10 -b ' + input.bam + " | " + 'samtools calmd - ' + fasta_file + " -e > " + forward_ma + ''' )2> ''' + samtools_calmd_log_F
		os.system(sam_call1)
		py_call1 = " ".join(["python", filterMA_py, "--input", forward_ma, "--output", forward_ma_py, "-c", min_aq, "-r", "no"])
		os.system(py_call1)
		
		# Generate the reverse strand calls by flipping the observed base
		sam_call2 = '(samtools view -f 0x10 -b ' + input.bam + " | " + 'samtools calmd - ' + fasta_file + " -e > " + reverse_ma + ''' )2> ''' + samtools_calmd_log_R
		os.system(sam_call2)
		py_call2 = " ".join(["python", filterMA_py, "--input", reverse_ma, "--output", reverse_ma_py, "-c", min_aq, "-r", "yes"])
		os.system(py_call2)
		
		# Link them together and clean up
		os.system("cat " + forward_ma_py + " " + reverse_ma_py + " > " + output.master_awk_out1)


# Next, filter these against known SNPs
rule filter_raw_awk:
	input:
		master_awk_out1 = outdir + '/temp/02_frombam/rawFromBam_' + "{chr}" + ".txt",
		read_barcode = outdir + "/temp/01_split/splitBam."+"{chr}"+".read_barcode.tsv.gz"
	output:
		master_awk_out2 = outdir + '/temp/03_processed/merged_' + "{chr}" + ".txt",
		readstats_log = outdir + '/logs/readstats/' + "quant1." + "{chr}" + ".txt"
	threads:
		1
	run:
		chr = wildcards.chr
		
		if(keep_positions != "none"):
			keep_positions_file = outdir + "/temp/01_split/keep_" + chr + ".tsv"
		else:
			keep_positions_file = "none"
			
		if(remove_positions != "none"):
			remove_positions_file = outdir + "/temp/01_split/remove_" + chr + ".tsv"
		else:
			remove_positions_file = "none"
		
		# Execute Rscript to merge (via read names) barcode tag with the SNP information
		
		r_call1 = " ".join(["Rscript", intersect_reads_edits_R, edit, input.master_awk_out1, input.read_barcode, keep_positions_file, remove_positions_file, output.master_awk_out2, output.readstats_log])
		os.system(r_call1)


# Final merge of the processed SNP files
rule final_merge:
	input:
		processed_read_files = processed_read_files
	output:
		final_edits = outdir + "/" + name + ".edits.tsv.gz"
	run:
		final_no_compress = outdir + "/" + name + ".edits.tsv"
		infiles = " ".join(processed_read_files)
		os.system("cat " + infiles + " > " + final_no_compress)
		os.system("gzip " + final_no_compress)
		
# Final merge of the processed SNP files
rule munge_qc:
	input:
		quants_1 = quant1s
	output:
		final_qc1 = outdir + "/" + name + ".qcQuant.tsv"
	run:
		r_call_qc = " ".join(["Rscript", munge_qc_edits_R, outdir + '/logs/readstats/' , output.final_qc1])
		os.system(r_call_qc)
