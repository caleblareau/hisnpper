import os
import subprocess
import shutil
import re
import pysam

from os.path import join

configfile: config["cfp"]     
script_dir = config["script_dir"]          
name = config["name"] 
fasta_file = config["fasta"] 

outdir = config["output"] 
haplotype_tag = config["haplotype_tag"] 
barcode_tag = config["barcode_tag"] 
min_aq = config["min_aq"] 

# Determine .bam files to execute for fragment overlap analysis
infile1 = outdir + "/.internal/chrs.txt"

with open(infile1) as f:
    chrs = f.readlines()

chrs = [x.strip() for x in chrs] 
raw_awk_files = [outdir + '/temp/02_frombam/rawFromBam_' + x + ".txt" for x in chrs] 
processed_read_files = [outdir + '/temp/03_processed/merged_' + x + ".txt" for x in chrs] 
quant1s = [outdir + '/logs/readstats/' + "quant1." + x + ".txt" for x in chrs] 

# File path to scripts
intersect_reads_R = script_dir + "/R/03_intersect_reads_SNPs.R"
munge_qc_R = script_dir + "/R/04_mungeQC1.R"

rule all:
	input:
		final_ase = outdir + "/" + name + ".ase.tsv.gz",
		final_qc1 = outdir + "/" + name + ".qcQuant.tsv"

# First up, pull out reads / bases that overlap reference Ns
rule pull_N_bp_chr:
	input:
		bam = outdir + "/temp/01_split/splitBam." + "{chr}" + ".bam",
	output:
		master_awk_out1 = outdir + '/temp/02_frombam/rawFromBam_' + "{chr}" + ".txt"
	threads:
		1
	run:
		chr = wildcards.chr
		
		# Pull reads with a matching N mask
		samtools_calmd_log = outdir + '/logs/samtools/' + "master_bam_parse." + chr + ".txt"
		line1 = '(samtools calmd ' + input.bam + ' ' + fasta_file +''' -e | awk '$5 > ''' + min_aq 
		line2 = '''  {print $0}' | awk 'BEGIN {OFS = FS = "\t" } ; {n=split($10,reads,""); split($11,qual,""); for (i=1; i <= length($10); i++) { if(reads[i] != "="){ print $3, $4, i, qual[i], reads[i], $1}} }' > '''
		line3 = output.master_awk_out1 + ''' )2> ''' + samtools_calmd_log
		sam_call1 = line1 + line2 + line3
		os.system(sam_call1)
		os.system("gzip " + samtools_calmd_log)

# Next, filter these against known SNPs
rule filter_raw_awk:
	input:
		snp = outdir + "/temp/01_split/SNPs_" + "{chr}" + ".tsv",
		master_awk_out1 = outdir + '/temp/02_frombam/rawFromBam_' + "{chr}" + ".txt",
		read_barcode = outdir + "/temp/01_split/splitBam."+"{chr}"+".read_barcode.tsv.gz"
	output:
		master_awk_out2 = outdir + '/temp/03_processed/merged_' + "{chr}" + ".txt",
		readstats_log = outdir + '/logs/readstats/' + "quant1." + "{chr}" + ".txt"
	threads:
		1
	run:
		chr = wildcards.chr
		
		# Execute Rscript to merge (via read names) barcode tag with the SNP information
		r_call1 = " ".join(["Rscript", intersect_reads_R, input.snp, input.master_awk_out1, input.read_barcode, output.master_awk_out2, output.readstats_log])
		os.system(r_call1)


# Final merge of the processed SNP files
rule final_merge:
	input:
		processed_read_files = processed_read_files
	output:
		final_ase = outdir + "/" + name + ".ase.tsv.gz"
	run:
		final_ase_no_compress = outdir + "/" + name + ".ase.tsv"
		infiles = " ".join(processed_read_files)
		os.system("cat " + infiles + " > " + final_ase_no_compress)
		os.system("gzip " + final_ase_no_compress)
		
# Final merge of the processed SNP files
rule munge_qc:
	input:
		quants_1 = quant1s
	output:
		final_qc1 = outdir + "/" + name + ".qcQuant.tsv"
	run:
		r_call_qc = " ".join(["Rscript", munge_qc_R, outdir + '/logs/readstats/' , output.final_qc1])
		os.system(r_call_qc)
